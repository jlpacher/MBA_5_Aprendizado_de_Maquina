{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwBxjsldSUXW"
   },
   "source": [
    "# Aprendizado de Máquina\n",
    "\n",
    "**Semana 3:** Avaliação de Desempenho Preditivo e Algoritmos de Aprendizado de Máquina\n",
    "\n",
    "**Tutor:** Fernando Pereira dos Santos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJV1E-qnTcYw"
   },
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yApqVIZYSUXY"
   },
   "source": [
    "Identificar qual a melhor abordagem para resolver um problema, em termos de complexidade e performance, é imprescindível dentre as muitas opções existentes na literatura. **Devido à grande quantidade de técnicas e combinações possíveis, avaliar e comparar os métodos empregados são de grande importância, tanto com o uso de métricas de performance, quanto em termos de complexidade.** \n",
    "\n",
    "Formas de avaliar um algoritmo de aprendizagem de máquina:\n",
    "- Erro (desempenho preditivo);\n",
    "- Custo (tempo de processamento e memória necessária);\n",
    "- Interpretabilidade.\n",
    "\n",
    "**Qual modelo proporciona a melhor performance?**\n",
    "\n",
    "**Qual modelo proporciona o menor custo computacional?**\n",
    "\n",
    "**Qual modelo devo escolher para resolver este problema?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-7FvGO9SUXY"
   },
   "source": [
    "# No Free Lunch:\n",
    "\n",
    "- **Não existe um único classificador que possa ser considerado ótimo para todos os problemas**, ou seja, o desempenho elevado em uma classe de problemas é compensado com um mau desempenho em outras classes. \n",
    "\n",
    "- Não há um princípio claro para se escolher um método ou um conjunto de métodos de aprendizagem, **raramente se tem um completo conhecimento da distribuição dos dados**, a tarefa de encontrar um bom e único classificador que solucione um determinado problema é muito difícil. \n",
    "\n",
    "- Nenhum classificador ou método de aprendizado deve ser preferido em relação a outro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdVUJtvbSUXZ",
    "outputId": "9e418df9-3488-485b-90d6-5acd633e8741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de dados IRIS (150, 4)\n",
      "Conjunto de rótulos IRIS (150,)\n",
      "Classes [0 1 2]\n",
      "\n",
      "Conjunto de dados WINES (178, 13)\n",
      "Conjunto de rótulos WINES (178,)\n",
      "Classes [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# carregando os datasets\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "Y_iris = iris.target\n",
    "print(\"Conjunto de dados IRIS\", X_iris.shape)\n",
    "print(\"Conjunto de rótulos IRIS\", Y_iris.shape)\n",
    "print(\"Classes\", np.unique(Y_iris))\n",
    "\n",
    "wines = load_wine()\n",
    "X_wines = wines.data\n",
    "Y_wines = wines.target\n",
    "print(\"\\nConjunto de dados WINES\", X_wines.shape)\n",
    "print(\"Conjunto de rótulos WINES\", Y_wines.shape)\n",
    "print(\"Classes\", np.unique(Y_wines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGzK6pQoUTLD",
    "outputId": "be8e52bf-0e95-4350-a4b7-30ca741d4d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia IRIS com K-NN: 0.9600 +/- 0.0327\n",
      "Acurácia IRIS com SVM: 0.9600 +/- 0.0327\n",
      "Acurácia IRIS com NB: 0.9467 +/- 0.0340\n",
      "\n",
      "Acurácia WINES com K-NN: 0.7127 +/- 0.0735\n",
      "Acurácia WINES com SVM: 0.9438 +/- 0.0395\n",
      "Acurácia WINES com NB: 0.9663 +/- 0.0211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#definição do cross-validation\n",
    "numeroFolds = 5\n",
    "kf = KFold(n_splits=numeroFolds, shuffle=True)\n",
    "\n",
    "#KFoldStratefied -> folds balanceados\n",
    "#100 exemplos (70 -30)\n",
    "#cada fold (14 - 6)\n",
    "\n",
    "#Ideia com conjunto de validação (100 exemplos - 5 folds):\n",
    "# Tr - Tr - Tr - Va - Te\n",
    "# Tr - Tr - Va - Te - Tr\n",
    "\n",
    "# Data Augmentation (gerar dados sintéticos para balancear o conjunto treinamento)\n",
    "\n",
    "#definição dos classificadores\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = SVC(kernel='linear')\n",
    "nb = GaussianNB()\n",
    "\n",
    "#classificação do conjunto IRIS\n",
    "scores = cross_val_score(knn, X_iris, Y_iris, cv=kf)\n",
    "print('Acurácia IRIS com K-NN: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
    "scores = cross_val_score(svm, X_iris, Y_iris, cv=kf)\n",
    "print('Acurácia IRIS com SVM: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
    "scores = cross_val_score(nb, X_iris, Y_iris, cv=kf)\n",
    "print('Acurácia IRIS com NB: %0.4f +/- %0.4f\\n' % (scores.mean(), scores.std()))\n",
    "\n",
    "#classificação do conjunto WINES\n",
    "scores = cross_val_score(knn, X_wines, Y_wines, cv=kf)\n",
    "print('Acurácia WINES com K-NN: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
    "scores = cross_val_score(svm, X_wines, Y_wines, cv=kf)\n",
    "print('Acurácia WINES com SVM: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))\n",
    "scores = cross_val_score(nb, X_wines, Y_wines, cv=kf)\n",
    "print('Acurácia WINES com NB: %0.4f +/- %0.4f' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAuNT1fseOni"
   },
   "source": [
    "# Ugly Duckling:\n",
    "\n",
    "O mesmo conceito se aplica para a representação dos atributos de um conjunto de dados: técnicas de extração de características podem ser eficientes para um cenário e nem tanto para outros\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luN1-4NifwrA"
   },
   "source": [
    "#Avaliação e comparação de modelos preditivos:\n",
    "\n",
    "Fontes de variação entre os classificadores:\n",
    "- **escolha do conjunto de teste:** diferentes conjuntos de teste podem proporcionar diferentes níveis de performance;\n",
    "- **escolha do conjunto de treinamento:** definição do conjunto de treinamento pode representar diferentes aprendizados no algoritmo;\n",
    "- **aleatoriedade interna do algoritmo de treinamento:** inicialização dos pesos nas redes neurais, por exemplo;\n",
    "- **aleatoriedade do erro de classificação:** variações de resposta devido às regras descritas no algoritmo implementado.\n",
    "\n",
    "---\n",
    "\n",
    "Para que a avaliação e comparação entre modelos seja justa é necessário:\n",
    "- pode-se variar valores de hiperparâmetros para cada modelo;\n",
    "- todas as execuções devem conter os mesmos dados;\n",
    "- os mesmos recursos computacionais devem estar disponíveis para todos os modelos;\n",
    "- a mesma métrica de avaliação deve ser utilizada.\n",
    "\n",
    "---\n",
    "\n",
    "A comparação de métodos pode ocorrer considerando técnicas diferentes ou considerando variações de uma mesma técnica:\n",
    "* **Hold-out**;\n",
    "* **Cross-validation**; \n",
    "  * **Jacknife**;\n",
    "* **Bootstrap**;\n",
    "* **Generalização**;\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcB0DcVnjpNv"
   },
   "source": [
    "# Generalização e desempenho preditivo:\n",
    "\n",
    "**Hold-out** (faz um split do conjunto de dados para treinamento e teste):\n",
    "- altamente dependente da sorte ou azar na definição dos conjuntos de treinamento e testes;\n",
    "- melhora com o uso de \"Random subsampling\" (gera-se várias partições aleatórias, em que os exemplos se misturam nas partições).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6r3D2e9mI_N",
    "outputId": "dd1521c4-5c24-4262-d867-927de7fe62d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hold-out com SVM: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_iris, Y_iris, test_size=0.5)\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "predTeste = svm.predict(x_test)\n",
    "teste_score = accuracy_score(predTeste, y_test)\n",
    "\n",
    "print(\"Hold-out com SVM:\", teste_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXm5rcHel83b"
   },
   "source": [
    "**Cross-validation** (k folds, sempre deixando um fold para teste e os demais para treinamento):\n",
    "- os folds são fixos durante todo o experimento;\n",
    "- considerar a taxa de exemplos classificados corretamente (acurácia, acurácia balanceada, etc);\n",
    "- média dos erros obtidos em diferentes execuções de um experimento (por exemplo, média da acurácia de 30 execuções);\n",
    "- temos a possibilidade de incluir um conjunto de validação proveniente do subconjunto de treinamento;\n",
    "- Execução:\n",
    "  *   Em verde: partes do conjunto de dados que serão utilizados como conjunto de treinamento;\n",
    "  *   Em vermelho: parte restante do conjunto de dados que será utilizado como conjunto de teste;\n",
    "  *   A média das performances indica uma generalização dos resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJpvEDpke_ui"
   },
   "source": [
    "![download.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUUAAAEUCAIAAAAzxLNYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAAUmSURBVHhe7doxSjTNGoDRr+8CdFyAkS5glmBiKJi6AFflAkwFQxN35t/Qlc1tM6Hr4RxohoIK3in6gYKZ5efn5x+Q8L/xCcxPz9ChZ+jQM3ToGUJ+dtze3YwdR3U+n8esF6YefuP8/9Te8PfXV2PHUf3+5uz+XrUsy9vXy1gc0uvje3L4jfP/U3vDr5N/Pz+NxSE9fHz+8ua4b0OHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ88Q8rPjdDqNHUe1TjhmvTD18Bvn/6f2hp/62FfL+oyNwOTct6FDz9ChZ+jQM3ToGTr0DCHbz1aXbu9uxo6jOp/PY9YLUw+/mfor3F9fjU1HtTf87G/O7u/Py7K8fb2MxSG9Pr4nh9/Mfv7fz09jcUgPH5//d/jZ3xz3bejQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06BlCfnacTqex46jWCcesF6YefuP8/9Te8FMf+2pZn7ERmJz7NnToGTr0DB16hg49Q4eeoUPPELL9DH3p9u5m7Diq8/k8Zr0w9fCb++ursfWokuc/+5uz+3+SZVnevl7G4pBeH9+Tw2/Wr/D9/DQWh/Tw8dk7/9nfHPdt6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGUJ+dpxOp7HjqNYJx6wXph5+4/z/1N7wUx/7almfsRGYnPs2dOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DOEbH8Tu3R7dzN2HNX5fB6zXri/vhqbjuqX4TdTn/+8w0997Kvd/3suy/L29TIWh/T6+P7L8N/PT2NxSA8fn3vDb2Y//0mHn/rYV+7b0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM4T87DidTmPHUa0TjlkvTD38xvn/qb3hpz721bI+YyMwOfdt6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWcI2f4mdun++mrsOKrz+TxmvXB7dzM2HdUvw2+m/grzDj/7m7P7f89lWb6fn8bikB4+Pn8Z/u3rZSwO6fXxfW/4zdRfYd7hZ39z3LehQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFn6NAzdOgZOvQMHXqGDj1Dh56hQ8/QoWfo0DN06Bk69AwdeoYOPUOHnqFDz9ChZ+jQM3ToGTr0DB16hg49Q4eeoUPP0KFnCPnZcTqdxo6jWiccs16YeviN8/9Te8NPfeyrZX3GRmBy7tvQoWfo0DN06Bkq/v37D2nbrnDYyC+pAAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC7T_Uyje-v4"
   },
   "source": [
    "Dados temporais: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n",
    "\n",
    "---\n",
    "\n",
    "**Jacknife** ou **leave-one-out**: k folds, sendo que k é a quantidade de exemplos do dataset.\n",
    "\n",
    "---\n",
    "\n",
    "**Bootstrap:** \n",
    "- alguns exemplos que estão no conjunto de dados podem não ser selecionados para o treinamento ou para o teste;\n",
    "- o mesmo objeto pode ser selecionado mais de uma vez para compor o conjunto de treinamento (os que sobrarem formam o conjunto de teste);\n",
    "- existem diversas heurísticas que atuam para selecionar os exemplos.\n",
    "\n",
    "https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.cross_validation.Bootstrap.html\n",
    "\n",
    "---\n",
    "\n",
    "**Generalização:** a capacidade de generalização de um método é uma das principais estimativas para se escolher um classificador em detrimento de outro, **sendo uma medida de divergência da performance alcançada com os dados de treinamento em relação a um conjunto de dados não vistos** durante este treinamento (testes).\n",
    "\n",
    "$Generalização = | performanceTR - performanceTE |$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pCDNwx3nNJ3",
    "outputId": "f8d4b0bc-3e21-4d88-bd26-2737c72ac5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento score SVM: 0.9833333333333333\n",
      "Teste score SVM: 0.9333333333333333\n",
      "Generalização SVM: 0.04999999999999993\n",
      "\n",
      "Treinamento score NB: 0.975\n",
      "Teste score NB: 0.9\n",
      "Generalização NB: 0.07499999999999996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_iris, Y_iris, test_size=0.2)\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "predTreino = svm.predict(x_train)\n",
    "predTeste = svm.predict(x_test)\n",
    "\n",
    "treinamento_score = accuracy_score(predTreino, y_train)\n",
    "teste_score = accuracy_score(predTeste, y_test)\n",
    "generalizacao = np.abs(treinamento_score-teste_score)\n",
    "\n",
    "print(\"Treinamento score SVM:\", treinamento_score)\n",
    "print(\"Teste score SVM:\", teste_score)\n",
    "print(\"Generalização SVM:\", generalizacao)\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "predTreino = nb.predict(x_train)\n",
    "predTeste = nb.predict(x_test)\n",
    "\n",
    "treinamento_score = accuracy_score(predTreino, y_train)\n",
    "teste_score = accuracy_score(predTeste, y_test)\n",
    "generalizacao = np.abs(treinamento_score-teste_score)\n",
    "\n",
    "print(\"\\nTreinamento score NB:\", treinamento_score)\n",
    "print(\"Teste score NB:\", teste_score)\n",
    "print(\"Generalização NB:\", generalizacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O_dgpGPo6L8"
   },
   "source": [
    "# Considerações finais:\n",
    "\n",
    "- Em **cenários críticos** qualquer ganho de performance pode compensar a complexidade do custo computacional; assim, o custo computacional é irrelevante à performance;\n",
    "- Todo o potencial de um modelo está diretamente relacionado aos atributos dos exemplos; **pré-processamento e a escolha adequada de extratores de características tem grande influência na performance dos modelos**;\n",
    "- Na avaliação da performance, **os classificadores só podem ser comparados justamente** se o conjunto de treinamento, o conjunto de teste e a métrica de performance são exatamente os mesmos."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AM_semana3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
