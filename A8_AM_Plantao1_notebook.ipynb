{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6qrf4oWZHU1"
   },
   "source": [
    "**Resumo do que abordaremos hoje:**\n",
    "\n",
    "- Árvores\n",
    "    - Quais são os parâmetros mais sensíveis\n",
    "    - Função de split\n",
    "    - Critérios de parada\n",
    "    - Notas sobre minha experiência pessoal\n",
    "- Ensembles\n",
    "    - Bagging\n",
    "- Viés e variância\n",
    "     - Demonstrar quando o bagging funciona e falha, de acordo com a variância do preditor\n",
    "- Random Patches\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tdmcYiqaHwQ"
   },
   "source": [
    "# 1. Árvores de decisão\n",
    "\n",
    "- Dividir para conquistar\n",
    "- Estruturas hierárquicas\n",
    "- Construção recursiva\n",
    "- Seleção de features:\n",
    "    - Quanto mais acima na árvore, mais importante\n",
    "    - O caminho da raíz à folha também pode ser utilizado como indicativo de importância\n",
    "- Interpretabilidade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hluRNxzQcTzU"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOr1Dxp5vV9I"
   },
   "source": [
    "## 1.1. Split na prática\n",
    "\n",
    "Vamos relembrar como os splits em uma árvore de decisão ocorrem na prática.\n",
    "\n",
    "Primeiro, vou escolher uma heurística de classificação para fazermos o teste.\n",
    "\n",
    "Por simplicidade, utilizarei a entropia e o ganho de informação:\n",
    "\n",
    "$E = -\\sum_i^C p_i\\log p_i$\n",
    "\n",
    "(caso com splits binários)\n",
    "\n",
    "$IG = E(y) - \\dfrac{|y_L|}{|y|}E(y_L) - \\dfrac{|y_R|}{|y|}E(y_R)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVTkWbQGxuI4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    n = len(y)\n",
    "    _, cnts = np.unique(y, return_counts=True)\n",
    "\n",
    "    entropy = 0\n",
    "    for c in cnts:\n",
    "        p_i = c / n\n",
    "        entropy += (p_i * np.log2(p_i))\n",
    "    return -entropy\n",
    "\n",
    "def info_gain(x, y, limiar):\n",
    "    n = len(y)\n",
    "    y_l = y[x <= limiar]\n",
    "    y_r = y[x > limiar]\n",
    "\n",
    "    return entropy(y) - (len(y_l) / n) * entropy(y_l) - (len(y_r) / n) * entropy(y_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C_vyr-m0z_z"
   },
   "source": [
    "Hora de testar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7lWrQaA02RX"
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(7)\n",
    "\n",
    "x = rng.uniform(-3, 3, 100)\n",
    "y = np.array(\n",
    "    [0 if xi <= 0 else 1 for xi in x]\n",
    ")\n",
    "x[:3], y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bntXONLl13C3"
   },
   "source": [
    "Para fazer um split numérico, a opção mais usual é testar todos os valores disponíveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHvAjp5Q1wgu"
   },
   "outputs": [],
   "source": [
    "def testa_todos(x, y, heuristica):\n",
    "    ordenados = sorted(x)\n",
    "\n",
    "    candidatos = [\n",
    "        (limiar, heuristica(x, y, limiar)) for limiar in ordenados\n",
    "    ]\n",
    "\n",
    "    return candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3-NF2d-2x5G"
   },
   "source": [
    "Vamos olhar nossos candidatos a split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgCll9rn21zB"
   },
   "outputs": [],
   "source": [
    "candidatos_split = testa_todos(x, y, info_gain)\n",
    "candidatos_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPjuBH8n3fFn"
   },
   "outputs": [],
   "source": [
    "def melhor_split(candidatos):\n",
    "    return max(candidatos, key=lambda c: c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk2jXLLg2EVv"
   },
   "outputs": [],
   "source": [
    "melhor_split(candidatos_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoZ8aJ7j2alM"
   },
   "source": [
    "Nossa implementação sempre selecionará o primeiro \"melhor candidato\", no caso de empates.\n",
    "\n",
    "Que tal olharmos um caso menos trivial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5Lap-v02rsL"
   },
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [0 if xi <= -2 or (xi > 0 and xi <= 0.5) or (xi > 1.5) else 1 for xi in x]\n",
    ")\n",
    "candidatos_split = testa_todos(x, y, info_gain)\n",
    "melhor_split(candidatos_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUn-YfAm7Zgh"
   },
   "source": [
    "Agora já sabemos como encontrar o melhor split, dada uma feature.\n",
    "\n",
    "Vamos fingir que nosso problema tivesse apenas uma feature. Vamos construir árvore com base em nossas ferramentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui0DwL4J70_3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_1dtree(x, y, heuristica, min_sample_split):\n",
    "    queue = [(x, y, 1)]\n",
    "\n",
    "    markers = {\n",
    "        0: \"o\",\n",
    "        1: \"^\"\n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "        0: \"blue\",\n",
    "        1: \"black\"\n",
    "    }\n",
    "    for c in np.unique(y):\n",
    "        x_aux = x[y == c]\n",
    "        plt.scatter(x_aux, [0 for _ in range(len(x_aux))], c=colors[c], marker=markers[c])\n",
    "\n",
    "\n",
    "    while len(queue) > 0:\n",
    "        x_aux, y_aux, alt = queue.pop(0)\n",
    "\n",
    "        # Número minimo de amostras\n",
    "        if len(x_aux) < min_sample_split:\n",
    "            continue\n",
    "        \n",
    "        # Partição homogênea\n",
    "        if len(np.unique(y_aux)) == 1:\n",
    "            continue\n",
    "\n",
    "        limiar, ig = melhor_split(testa_todos(x_aux, y_aux, heuristica))\n",
    "\n",
    "        plt.axvline(limiar, ymax=alt)\n",
    "\n",
    "        x_l, y_l = x_aux[x_aux <= limiar], y_aux[x_aux <= limiar]\n",
    "        queue.append((x_l, y_l, alt * 0.9))\n",
    "        x_r, y_r = x_aux[x_aux > limiar], y_aux[x_aux > limiar]\n",
    "        queue.append((x_r, y_r, alt * 0.9))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qsa1OwAD-_AS"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx8Wmj19BZeB"
   },
   "outputs": [],
   "source": [
    "y = rng.choice([0, 1], p=[0.5, 0.5], size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imtUy9vQAz8T"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8bpmAhtBzQg"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9rgqyBPB355"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWbvLvQWCKvN"
   },
   "source": [
    "### 1.1.1. E regressão, como fica?\n",
    "\n",
    "Em regressão temos um target continuo. Logo, outros tipos de heurísticas devem ser utilizadas.\n",
    "\n",
    "Ilustrarei uma das heurísticas, que é equivalente à operação padrão utilizada no `sklearn`.\n",
    "\n",
    "Redução de variância:\n",
    "\n",
    "$VR = Var(y) - \\dfrac{|y_l|}{|y|}Var(y_l) - \\dfrac{|y_r|}{|y|}Var(y_r)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGz0IHoaDgEQ"
   },
   "outputs": [],
   "source": [
    "def vr(x, y, limiar, min_sample_split=5):\n",
    "    n = len(y)\n",
    "    vr = np.var(y, ddof=1)\n",
    "    y_l = y[x <= limiar]\n",
    "    y_r = y[x > limiar]\n",
    "\n",
    "    if len(y_l) < min_sample_split or len(y_r) < min_sample_split:\n",
    "        return 0\n",
    "\n",
    "    vr -= (len(y_l) / n) * np.var(y_l, ddof=1)\n",
    "    vr -= (len(y_r) / n) * np.var(y_r, ddof=1)\n",
    "\n",
    "    return vr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LydqZ_IpEH7z"
   },
   "outputs": [],
   "source": [
    "y = np.zeros(len(x))\n",
    "\n",
    "y[x <= 0] = rng.normal(-1, 0.1, size=len(np.where(x <= 0)[0]))\n",
    "y[x > 0] = rng.normal(1, 0.1, size=len(np.where(x > 0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auoEFp7rFOZB"
   },
   "outputs": [],
   "source": [
    "split = melhor_split(testa_todos(x, y, vr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUIYr7C6FOlE"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.axvline(split[0], ymin=min(y), ymax=max(y), c=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3q4CpGcScd2Z"
   },
   "source": [
    "## 1.2. Notas sobre as árvores no sklearn\n",
    "\n",
    "Alguns insights que obtive com a experiência.\n",
    "\n",
    "### 1.2.1. As árvores não são determinísticas\n",
    "\n",
    "O sklearn implementa (de forma muito rápida e elegante) as suas estruturas de árvore. De fato, todos os algoritmos de ensemble compartilham do mesmo preditor base.\n",
    "\n",
    "Para usar a mesma árvore por si só, nas Random Forest e Extra Trees, além de todos os algorítmos de boosting, devem existir prós e contras.\n",
    "\n",
    "- Por padrão, o sklearn utiliza todas as features para avaliar splits\n",
    "    - No entanto, devido aos ensembles, subsets das features podem ser utilizadas\n",
    "- As features são sempre embaralhadas por padrão\n",
    "    - Se duas features são igualmente \"boas\" (de acordo com o critério de split) elas podem ser permutadas entre múltiplas execuções\n",
    "- **Solução:** Sempre fixar a seed de geração de números aleatórios (`random_state`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUyeVzbrfkaH"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "X = np.zeros((1000, 4))\n",
    "\n",
    "X[:, 0] = rng.normal(0, 1, 1000)\n",
    "X[:, 1] = rng.normal(1, 3, 1000)\n",
    "X[:, 2] = X[:, 0]\n",
    "X[:, 3] = X[:, 1]\n",
    "\n",
    "y = rng.choice([0, 1], size=1000, p=[0.3, 0.7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ht8RAW3iOl9"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=7, max_depth=2)\n",
    "dt.fit(X, y)\n",
    "\n",
    "r = export_text(dt, feature_names=[\"A\", \"B\", \"C\", \"D\"])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNimr0CZi1AF"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=10001, max_depth=2)\n",
    "dt.fit(X, y)\n",
    "\n",
    "r = export_text(dt, feature_names=[\"A\", \"B\", \"C\", \"D\"])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI8EGsMerur9"
   },
   "source": [
    "### 1.2.2. A configuração padrão do sklearn tem grandes chances de gerar overfitting\n",
    "\n",
    "Por padrão, o `sklearn` não restringe em basicamente nada as suas árvores.\n",
    "Não tem problema algum nisso, mas devemos ficar \"espertos\" para utilizar as árvores.\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr14r0iUsSz_"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuDGwgQxtgng"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_train, dt.predict(X_train)), accuracy_score(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vA2x0Bztt8Nm"
   },
   "outputs": [],
   "source": [
    "dt.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "expFWEzhuUbL"
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_train, dt.predict(X_train)), accuracy_score(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkAn2UOiu63H"
   },
   "outputs": [],
   "source": [
    "dt.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM72PoNQvdKt"
   },
   "source": [
    "## 1.3. Ajuste de hiper-parâmetros\n",
    "\n",
    "As árvores contam com vários parâmetros para ajuste. Mas quais são mais interessantes de focar?\n",
    "\n",
    ">  Em geral, queremos restringir as árvores (especialmente de uma forma \"esperta\") para que possamos evitar overfitting.\n",
    "\n",
    "Dentre os parâmetros que valem a pena checar:\n",
    "\n",
    "- `max_depth`\n",
    "- `min_samples_split`\n",
    "- `min_samples_leaf`\n",
    "- `min_weight_fraction_leaf`\n",
    "- `max_leaf_nodes`\n",
    "- `min_impurity_decrease`\n",
    "- `ccp_alpha`\n",
    "\n",
    "Várias possibilidades!\n",
    "\n",
    "Na minha humilde opinião, nem todos precisam ser ajustados ao mesmo tempo. Em minha visão, esses hiper-parâmetros poderiam ser agrupados. Uma possibilidade seria ajustar um grupo de parâmetros, ou até mesmo uma combinação de grupos.\n",
    "\n",
    "Eis aqui a minha visão pessoal:\n",
    "\n",
    "1. Pré-poda:\n",
    "    - **A:** limitação \"cega\" - não leva em conta as heurísticas de split\n",
    "        - `max_depth`, `max_leaf_nodes`\n",
    "    - **B:** limitação que não leva as heurísticas de split diretamente em conta\n",
    "        - `min_samples_leaf`, `min_samples_split`, `min_weight_fraction_leaf`\n",
    "    - **C:** limitação que considera as heurísticas de split\n",
    "        - `min_impurity_decrease`\n",
    "2. Pós-poda:\n",
    "    - `ccp_alpha`\n",
    "\n",
    "---\n",
    "\n",
    "Questão para reflexão:\n",
    "\n",
    "> Qual a diferença prática entre as estruturas geradas por uma árvore restringida via altura máxima e as outras estratégias?\n",
    "\n",
    "---\n",
    "\n",
    "De resto, as técnicas de ajuste de hiper-parâmetro se aplicam como usual.\n",
    "\n",
    "**Obs:**\n",
    "\n",
    "> É possível dar pesos diferentes para as classes -> cenários com desbalanceamento, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HnmTzkOvsZQ"
   },
   "source": [
    "# 2. Viés e variância revisitados: ensembles baseados em Bagging\n",
    "\n",
    "- Redução da variância\n",
    "- Vimos no começo do curso que a variância e o viés se contrapoem:\n",
    "    - Se aumentamos o viés, diminuímos a variância. E vice-versa.\n",
    "\n",
    "- Viés alto -> underfitting\n",
    "- Variância alta -> overfitting\n",
    "\n",
    "A princípio, overffiting parece algo sempre \"maléfico\", mas no quesito dos ensembles baseados em bagging, esse sobreajuste pode vir a calhar.\n",
    "\n",
    "Por que as árvores de decisão são tão populares em ensembles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpCL_bKovxSv"
   },
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, dt.predict(X_test)), dt.get_depth(), dt.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPwLwb8-vOvE"
   },
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=43, shuffle=True)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, dt.predict(X_test)), dt.get_depth(), dt.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct1godTSveKb"
   },
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=44, shuffle=True)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, dt.predict(X_test)), dt.get_depth(), dt.get_n_leaves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FinTlaibvngp"
   },
   "source": [
    "Por que isso acontece? Vamos voltar ao nosso exemplo lá do início do plantão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZQUO8PHvi3j"
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(7)\n",
    "\n",
    "x = rng.uniform(-3, 3, 100)\n",
    "y = np.array(\n",
    "    [0 if xi <= 0 else 1 for xi in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foppBL7-IjFC"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Cc_StRJIz0g"
   },
   "source": [
    "Deixa eu bagunçar um pouco esses dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jY73GeQYI9Qx"
   },
   "outputs": [],
   "source": [
    "np.where(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdxoeCPYJe23"
   },
   "outputs": [],
   "source": [
    "# Selecionei 3 posições arbitrárias para permutar as labels\n",
    "y[np.array([9, 87, 94])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlMdPqxcJ2_I"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3JnZl2nJ5s9"
   },
   "source": [
    "Desafio:\n",
    "\n",
    "> O que está acontecendo?\n",
    "\n",
    "E se restringirmos as coisas (nesse caso, restringirmos bastante)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-mAE2jiKPfA"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cz5KbN8SKjCj"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxUdw8K9Kk-Z"
   },
   "outputs": [],
   "source": [
    "plot_1dtree(x, y, info_gain, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX_vtK9eKI0z"
   },
   "source": [
    "Uma pequena mudança nos dados acarreta grandes mudanças no modelo gerado!\n",
    "\n",
    "Alta variância! :)\n",
    "\n",
    "---\n",
    "\n",
    "Que lições podemos tomar disso já de antemão se formos pensar em ensembles com bagging?\n",
    "\n",
    "> Pode ser uma boa ideia deixar as árvores em um ensemble baseado em bagging \"voarem livres\" ou com pouca restrição.\n",
    "\n",
    "**Por quê?**\n",
    "\n",
    "---\n",
    "\n",
    "Note que a Random Forest e outros ensembles similares utilizam mais de uma estratégia para induzir diversidade entre seus membros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsKuTBq_wELB"
   },
   "source": [
    "# 3. Comparando o efeito de bagging em algoritmos de AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Lx5bEK1wKgE"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXzsKHTINC0q"
   },
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "\n",
    "kf = KFold(10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maCSloNLOYrM"
   },
   "source": [
    "## 3.1. Árvores de decisão\n",
    "\n",
    "Vamos avaliar o efeito do bagging em algumas famílias de algoritmos preditivos.\n",
    "\n",
    "### 3.1.1. Individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pAEdXk7NVWA"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    DecisionTreeClassifier(random_state=7),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekVmwxGBODW2"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    DecisionTreeClassifier(random_state=7, min_impurity_decrease=0.001),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pgh_Ys82Oe87"
   },
   "source": [
    "### 3.1.2. Bagging\n",
    "\n",
    "Sem restrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFrG9OKCN8VF"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        DecisionTreeClassifier(random_state=7),\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K25a5gm0PDwt"
   },
   "source": [
    "Restringindo a profundidade máxima da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aatBRjZRPGzP"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        DecisionTreeClassifier(random_state=7, max_depth=5),\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDr73EKqPXKe"
   },
   "source": [
    "**Desafio:**\n",
    "\n",
    "> O que está acontecendo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQAHPzVMUV7u"
   },
   "source": [
    "## 3.2 Redes Neurais\n",
    "\n",
    "Não irei me aprofundar nas configurações das redes de forma alguma. O objetivo aqui é apenas ilustrativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPbvVTU_Pb6U"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXYozwKmUvMu"
   },
   "source": [
    "### 3.2.1. Individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGtpVJ-IVGf2"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    MLPClassifier(random_state=1),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5rlP2qJVztO"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    MLPClassifier(random_state=2),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PseRulEfV_AT"
   },
   "source": [
    "### 3.2.2. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_5-fvfVVZLy"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        MLPClassifier(random_state=1),\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDNxLiTJWsjj"
   },
   "source": [
    "## 3.3. k-NN\n",
    "\n",
    "Quais são as apostas para o k-NN?\n",
    "\n",
    "### 3.3.1. Individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxSLSFQWXW1T"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "accs = cross_val_score(\n",
    "    KNeighborsClassifier(),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1t4ejITWtRV"
   },
   "source": [
    "### 3.3.2. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrwG3jz6Xy-8"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        KNeighborsClassifier(),\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZ-tZBDdWs_D"
   },
   "source": [
    "## 3.4. Naive Bayes\n",
    "\n",
    "### 3.4.1. Individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egBpJ19rYCFl"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "accs = cross_val_score(\n",
    "    GaussianNB(),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng--MjYdW9Hx"
   },
   "source": [
    "### 3.4.2. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4OJXwDfYMkV"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        GaussianNB(),\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOWKFaBRXBUJ"
   },
   "source": [
    "## 3.5. Regressão Logistica\n",
    "\n",
    "Façam suas apostas!\n",
    "\n",
    "### 3.5.1. Individualmente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btVocHZJYb5m"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "accs = cross_val_score(\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=1, max_iter=200))\n",
    "    ]),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFC3J7MoXBmb"
   },
   "source": [
    "### 3.5.2. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAlOuREAXLxQ"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', BaggingClassifier(LogisticRegression(random_state=1, max_iter=200), random_state=42))\n",
    "    ]),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEQJN2zRaQME"
   },
   "source": [
    "# 4. Random Patches\n",
    "\n",
    "Até o momento, nós focamos em apenas uma estratégia de perturbação nos dados:\n",
    "\n",
    "> Bagging\n",
    "\n",
    "Induzir diversidade.\n",
    "\n",
    "Existem mais formas de fazer isso. Outra forma muito popular é a utilização de sub-conjuntos de features para induzir cada preditor.\n",
    "\n",
    "**Atenção:**\n",
    "\n",
    "- Bagging: amostragem com reposição\n",
    "- Sub-conjuntos de features: amostragem sem reposição (abordagem mais usual)\n",
    "\n",
    "---\n",
    "Qual é o efeito de sub-amostrarmos features?\n",
    "\n",
    "- O que acontece em uma árvore de decisão?\n",
    "- O que acontece no k-NN?\n",
    "- Quando isso pode ser mais ou menos efetivo?\n",
    "\n",
    "---\n",
    "\n",
    "A combinação de bagging e sub-conjuntos de features por preditor base resulta no algorítmo chamado: *Random Patches*.\n",
    "\n",
    "**Atenção (de novo):**\n",
    "\n",
    "> A sub-amostragem de features por preditor base é **global** no Random Patches.\n",
    "\n",
    "Vamos ver na prática:\n",
    "\n",
    "## 4.1. Árvores de Decisão + Bagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG-bJGCjeXIw"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        DecisionTreeClassifier(random_state=1),\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu4J6HciekM7"
   },
   "source": [
    "## 4.2. Árvores de Decisão + Random Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGUUk7u8d2sj"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    BaggingClassifier(\n",
    "        DecisionTreeClassifier(random_state=1),\n",
    "        random_state=42,\n",
    "        max_features=round(0.6 * dataset.data.shape[1])\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoAGEIhBaTBd"
   },
   "source": [
    "# 5. Random Forest\n",
    "\n",
    "O Random Patches, por fazer sub-amostragem de features a nível global, pode ser aplicado a qualquer algoritmo.\n",
    "\n",
    "A Random Forest vai um passo além, no quesito indução de diversidade.\n",
    "\n",
    "Ao invés de subamostrar features globalmente, as RFs\n",
    "\n",
    "> Realização a sub-amostragem de features a nível **local**\n",
    "\n",
    "Mas como?\n",
    "\n",
    "Durante cada tentativa de split, em cada nó, um novo sub-conjunto de features é amostrado (sem reposição).\n",
    "\n",
    "---\n",
    "\n",
    "**Desafio:**\n",
    "\n",
    "> Qual a vantagem de se fazer isso?\n",
    "\n",
    "---\n",
    "\n",
    "Em contrapartida, agora estamos limitados a árvores de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxLN6sbMaW_N"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accs = cross_val_score(\n",
    "    RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        max_features=round(0.6 * dataset.data.shape[1]),\n",
    "        n_estimators=10\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tyTa8BUisCa"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qNWPUGBjK9X"
   },
   "source": [
    "## 5.1. E agora? E para tunar?\n",
    "\n",
    "As RFs contam com vários parâmetros por si só, e ainda trazem os parâmetros dos modelos base (árvores). E agora?\n",
    "\n",
    "Aqui vai uma pitada da minha experiência pessoal. O que focar?\n",
    "\n",
    "- `n_estimators`: no entanto, existe um ponto de saturação\n",
    "    - mais árvores != mais acurácia. Isso é até bom!\n",
    "- `max_features`: eu diria que esse é o parâmetro mais sensível\n",
    "\n",
    "O paper do Breiman introduzindo as RFs foca nesses dois parâmetros.\n",
    "\n",
    "Desconheço a existência de consenso quanto as vantagens (ou desvantagens) de se podar as árvores na floresta. O que eu faço normalmente? Deixo as árvores crescerem sem restrições.\n",
    "\n",
    "Um coisa incrível sobre as RFs? O desempenho delas normalmente não varia muito após o ajuste de hiper-parâmetros.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "Ao se deparar com um novo problema eu costumo:\n",
    "\n",
    "1. Testar um baseline simples\n",
    "2. Testar um modelo linear\n",
    "3. Testar uma RF com os hiper-parâmetros padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EZKISlzkx8M"
   },
   "source": [
    "## 5.2. Feature importance\n",
    "\n",
    "Existem algumas maneiras de se estimar a importância das features a partir de uma floresta de árvores. Por padrão, o `sklearn` utiliza um algoritmo de calculo de importância baseado na some do decréscimo médio na impureza de cada árvore.\n",
    "\n",
    "Para utilizá-lo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFPcNXpUpt7M"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()\n",
    "\n",
    "# Não me julguem por usar o conjunto inteiro, o propósito é fazer algo didático\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZAX0Gbfphve"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Opcional, mas interessante\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "importances = pd.Series(importances, index=dataset.feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importance\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Diz7lxbEnPP2"
   },
   "source": [
    "Eu vou descrever uma alternativa mais custosa, porém mais confiável. Esse algoritmo para cálculo de importância das features é descrito no artigo do Breiman, onde as Random Forest (também) foram introduzidas.\n",
    "\n",
    "---\n",
    "\n",
    "O Bagging nos dá algo de brinde:\n",
    "\n",
    "- Cada árvore tem um conjunto de amostras que nunca foi utilizado para treino: amostras Out-of-Bag (OOB).\n",
    "- Com as amostras OOB podemos calcular OOBE (e essa estimativa não é enviesada, como treinar e testar com os mesmos dados!)\n",
    "\n",
    "Com esses ingredientes, podemos dar um passo além e estimarmos uma medida de importância de feature:\n",
    "\n",
    "**RF Feature Importance (Permutation):**\n",
    "\n",
    "1. Para cada feature:\n",
    "    1. Calcule o OOBE\n",
    "    2. Permute os valores da feature aleatoriamente\n",
    "    3. Recalcule o OOBE para os dados permutados\n",
    "    4. Calcule a diferença\n",
    "2. (Opcional) Normalize os valores obtidos\n",
    "\n",
    "O `sklearn` não implementa essa opção diretamente. A implementação padrão de RF no R tem essa opção.\n",
    "\n",
    "No entanto, podemos simular algo parecido essa estratégia utilizando a função `permutation_importance` ([link](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html)), que está disponível no módulo `inspection` do `sklearn`. No entanto, precisamos passar um conjunto de testes para o cálculo das importâncias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkCbtiLLrZuc"
   },
   "source": [
    "## 5.3. E dá para \"bagunçar\" mais?\n",
    "\n",
    "Até agora a nossa \"receita\" de ensemble inclui:\n",
    "\n",
    "- `n_estimators` preditores com alta variância (de preferência árvores de decisão)\n",
    "- bagging\n",
    "- sub-amostragem (local, no caso de árvores) de features\n",
    "\n",
    "No caso da RF, temos que em cada split um novo su-conjunto de features é amostrado e o melhor ponto, dentre a melhor das features é selecionada para criar um nó de decisão.\n",
    "\n",
    "Como poderíamos deixar mais aleatório esse processo?\n",
    "\n",
    "> Extra Trees!\n",
    "\n",
    "- Usa sub-conjuntos de features assim como a RF, no entanto, os pontos de split também são aleatórios!\n",
    "- Escolhe o melhor ponto aleatório de split no sub-conjunto de features selecionadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp3CZHCepdkb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "accs = cross_val_score(\n",
    "    ExtraTreesClassifier(\n",
    "        random_state=42\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcJsAYkgmzb9"
   },
   "source": [
    "Por padrão, as Extra Trees não usam Bagging (bootstrap sampling). Mas esse padrão pode ser modificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVadKlmWm7Mo"
   },
   "outputs": [],
   "source": [
    "accs = cross_val_score(\n",
    "    ExtraTreesClassifier(\n",
    "        random_state=42,\n",
    "        bootstrap=True\n",
    "    ),\n",
    "    X=dataset.data,\n",
    "    y=dataset.target,\n",
    "    cv=kf,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCRGdrhXn1CH"
   },
   "source": [
    "Qual é o impacto da mudança na estratégia de particionamento das árvores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5220lXGbpbbf"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=5000, n_features=20, n_classes=5, n_informative=15,\n",
    "    random_state=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuoTsKopn8y8"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvnwiLNQoJxy"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "xt = ExtraTreesClassifier(random_state=42)\n",
    "xt.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "08-tutoria-arvores-ensembles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
